% !TEX root = ../thesis.tex

\section{Objectives and research questions}%
\label{sec:objectives}





% Illustrates the objectives and research questions underpinning the PhD project to demonstrate that the papers form a coherent body of work.




%%% meta objective

- link to replication crisis - see davidthesis


- vision ahead of reality

\begin{itemize}
    \item I use a single dataset, provided by Money Dashboard, for all three
        papers.

    \item The data presented a number of challenges.

    \item Handling data of this size.

    \item Secure storage with easy remote access (AWS).

    \item Consistenc and efficient preprocessing (my process).

    \item Open science contribution: all work available on Github, code
        available for preprocessing from beginning to end.
\end{itemize}

\paragraph{Motivation:}%
\label{par:motivation_}

My experience as a researcher in well-known academic and private-sector
institutions has made clear to me over the years that careful, reliable, and
replicable data preprocessing is undervalued in many settings.

The result are plain data errors that overturn results (Reinhard and Rogoff)
and replication issues (see Ariely controversies). Given my experience, I'd
think that all we know is the tip of the iceberg.

In the vast majority of empirical research projects there is no good reason to
not make the code public, even when the data is proprietary. And yet, for the
vast majority of papers, there is no code available to replicate findings and
check precise implementation details, which often matter but are not described
in papers.

All of this harms science - the quality of it and the trust in it.

I have dedicated a lot of time during my PhD to ensure that I can rectify at
least some of those issues.

The code for all my projects is available online and includes scripts that can
be used to easily run the entire analysis.

